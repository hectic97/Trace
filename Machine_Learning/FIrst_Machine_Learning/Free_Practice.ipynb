{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>문장</th>\n",
       "      <th>혐오 여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>지금 어디 계세요?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>한국 시간에 시계 맞췄어?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>햄버거 두 개랑 콜라 주세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>우리는 밤새 춤추고 노래했다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>무엇보다도, 스트레스를 줄이는 것이 중요합니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          문장  혐오 여부\n",
       "0           0                  지금 어디 계세요?      0\n",
       "1           1              한국 시간에 시계 맞췄어?      0\n",
       "2           2            햄버거 두 개랑 콜라 주세요.      0\n",
       "3           3            우리는 밤새 춤추고 노래했다.      0\n",
       "4           4  무엇보다도, 스트레스를 줄이는 것이 중요합니다.      0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data/hate_speech_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=TfidfVectorizer(max_df=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['문장'].values\n",
    "y=df.iloc[:,-1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit(X_train)\n",
    "new_X_train=vect.transform(X_train)\n",
    "new_X_test=vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.804"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train=new_X_train.toarray()\n",
    "X_test=new_X_test.toarray()\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "lr.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text=df['문장']\n",
    "y=df['혐오 여부']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traint,X_testt,y_train,y_test=train_test_split(X,y,test_size=.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=make_pipeline(TfidfVectorizer(),LogisticRegression(max_iter=2500))\n",
    "params={'logisticregression__C':[0.1,1,10,100],\n",
    "       'tfidfvectorizer__min_df':[1,3,5],\n",
    "       'tfidfvectorizer__max_df':[0.05,0.1,0.5,0.8],\n",
    "       'tfidfvectorizer__ngram_range':[(1,1),(1,2)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidfvectorizer',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None...\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'logisticregression__C': [0.1, 1, 10, 100],\n",
       "                         'tfidfvectorizer__max_df': [0.05, 0.1, 0.5, 0.8],\n",
       "                         'tfidfvectorizer__min_df': [1, 3, 5],\n",
       "                         'tfidfvectorizer__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid=GridSearchCV(pipe,param_grid=params,cv=5)\n",
    "grid.fit(X_traint,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8451219512195122\n",
      "{'logisticregression__C': 1, 'tfidfvectorizer__max_df': 0.05, 'tfidfvectorizer__min_df': 1, 'tfidfvectorizer__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.05, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=2500,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=pred.predict(X_testt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['내일 저녁에 뭐 하세요?', '이 오렌지 신선한 건가요? ', '아빠는 언제 돌아와?',\n",
       "       '형냐 목욕탕 가서 젊은 여자 없다고 투덜대려고 그고생한거야?', '공원에서 오른쪽으로 도세요.',\n",
       "       '오늘은 쉬는 날이야.', '아이큐 높을수록 혼자 잘지낸다는 연구결과있노', '아이들이 놀이터에 모였다.',\n",
       "       '눈이 녹아서 길이 굉장히 미끄러워졌어.', '커피 한 잔 하시겠어요?', '실례지만,? 몇 시인지 아세요?',\n",
       "       '커피를 마시면 밤에 잠이 안 와요.', '나는 가끔 맥주를 마신다.', '그거 어때? - 나쁘지 않네.',\n",
       "       '3월1일은 한국에서 공휴일이다.', '먼저 가.', '교실에는 남학생이 거의 없었어.',\n",
       "       '너무 비싸지 않아?? 더 싼 걸 찾아봐.', '니 칫솔을 썼더니 기분이 이상해.',\n",
       "       '우리나라에서는 태어나면 바로 한 살이에요. ', '일본에 가려면 관광 비자가 필요해요.',\n",
       "       '분명히 내 몸은 선진국에 있는데 내 몸은 좆국이노. ', '내 아내는 내가 꿈꾸던 바로 그 사람이다.',\n",
       "       '우리는 밤새 춤추고 노래했다.', '나 고양이 키우고 싶어.', '그 사람 어떻게 생겼어요?',\n",
       "       '나는 구두 공장에서 일했어.', '이번 달에는 언제 보름달을 볼 수 있어요?', '저는 양의 해에 태어났어요.',\n",
       "       '이 방에서 회의를 하고 싶어.', '길을 막고 거기 서 있지 마라.', '5천년 역사 풉~풉~~',\n",
       "       '바다에 도착하면 마음이 바뀔지도 몰라.', '갑자기 날씨가 추워지고 있어.',\n",
       "       '그 차가 나를 쳤을 때, 나는 심한 충격을 받았다.', '거기 가운데 앉아라.', '안전벨트 풀어도 돼요?',\n",
       "       '이 빨래는 몇 번 헹궈야 하죠? ', '라면 한 그릇 어때?', '할머니가 어젯밤 돌아가셨어요.',\n",
       "       '내년에 발레 배우러 러시아에 갈 거야.', '정말 맛있네요!', '왜 많은 사람들이 담배를 피울까요? ',\n",
       "       '너 약속 지키는 거, 난 한 번도 못 봤어. ', '내가 이 일을 맡을게.', '판다가 주로 뭘 먹는지 알아?',\n",
       "       '경찰에 전화는 했어?', '너 오늘 우울해 보여.', '저새낀 왜 혼자 부랄발작하노 똥내 오져벌임',\n",
       "       '무슨 회사 남자들이 뭘 다 도와주는데? 뭐 집사줌? 차사줌? 립스틱 하나라도 사줌? 냄져들이랑 연락해바짜 암바께 더걸림?',\n",
       "       '제가 나이보다 어려보인다는 소리 많이 들어요.', '서랍 안이 아니라 책상 위에 있었어요.',\n",
       "       '몇 시야? - 3시 40분.', '10분 후에 다시 전화할게.', '말하고 글 중에 어느 것이 더 중요한가요?',\n",
       "       '원래 자지값은 똥값이라 인기가 없어. 그대로 고독사하는 쀼젤^오^', '저희 은행에 계좌를 갖고 계신가요? ',\n",
       "       '너 왜 재즈를 싫어하는 거야?', '혜안이 전화했었다고 전해 주세요.', '이 물건들은 모양이 다르다.',\n",
       "       '손 들어!', '나는 비빔밥이 별로야.', '저 부부는 취미가 비슷해요, 자는 거요.', '고기 몇 마리 잡았어?',\n",
       "       '수업 중에 떠들지 마라.', '자꾸 물어보지 마.', '그날 밤 너는 뭘 하고 있었어?', '요즈음 살이 쪄.',\n",
       "       '아래에 서명해 주세요.', '나는 베토벤을 제일 좋아해. ', '찌개는 식으면 맛이 없어.',\n",
       "       '저기 있는 여자 보여?', '자동차에 또 문제가 있어요?',\n",
       "       'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 부랄도 얼마나 좆만하면 톡 톡 터지노', '보통 몇 시에 주무세요?',\n",
       "       '저 식당은 냉면으로 유명해.', '경찰이 그 사건을 조사하고 있어요.', '무슨 일이 있었는지 설명해 주시겠어요?',\n",
       "       '저기에 주유소가 있어요.', '나 여기 서점에 있어. ', '어느 쪽이 남쪽이야?',\n",
       "       '아니요, 그 애는 내 아들이 아니에요.', '더 이상은 안 돼. 최대한 빨리 가고 있다고.',\n",
       "       '내게 생체딜도와 같은 와꾸를 들고 오던가 or 하룻밤 장난감이 되어줄 수 없다면 돈만 내고 꺼져 ',\n",
       "       '어느 커플이 서로를 사랑스럽게 바라보고 있었다.', '한강은 서울시를 통과하여 흐른다.',\n",
       "       '한국은 여름에 굉장히 더워요.', '하루에 열두 시간 일하고 쉴 시간도 없어요.', '이 근처에 사니?',\n",
       "       '수업은 오전 8시에 시작한다.', '저을대 유포하지않고 혼자 소장만 할거^솣^',\n",
       "       '고향에 오래간만에 오신 건가요? ', '어젯밤부터 가슴이 아파요.', '영어 교과서 10페이지를 펴세요.',\n",
       "       '나는 와인 한 병을 다 마신 후 운전을 했다.', '아주 쉬워.', '의사 선생님은 지금 다른 환자를 보고 계세요.',\n",
       "       '너무 싱거우면, 소금을 넣어라.', '사람이 아닌데 왜 말을하지? 수준이노 조팔',\n",
       "       '요즘 한국에는 중국어를 공부하는 사람들이 많다.', '그녀의 말은 사실과 전혀 달라.',\n",
       "       '이상하게 들릴지도 모르지만, 내가 한 말은 사실입니다.', '나 지금 우체국 가는 길이야. ',\n",
       "       '15세에, 그는 대학에 들어갔다.', '대학 졸업하고 뭐 할 거야?',\n",
       "       '우리 애가 벌써 커서, 이 옷이 맞지 않을 정도로 커졌다.',\n",
       "       '중급식때 133, 3% 이내였는데 무슨 식인지 몰랐노 학교에서는 주로 웩슬러식이노?',\n",
       "       '그 영화에서 가장 좋은 부분이 뭐였어?', '열어 봐. 깜짝 선물이야. ',\n",
       "       '그는 우연히 알려지지 않은 동물을 발견했다.', '매우 추워요.', '몇 층 가세요?',\n",
       "       '모두 다 왔을 때 파티는 거의 다 끝나 있었다.', '올해는 담배를 끊기로 결심했어요.',\n",
       "       '나는 여름이 좋아. 여름에는 수영을 할 수 있으니까.', '이번 역은 종각역입니다. 내리실 문은 왼쪽입니다 ',\n",
       "       '아버지는 무슨 일을 하시니?', '그 선수는 수건으로 얼굴의 땀을 닦았다.', '이 도시는 살기 좋은 곳이다.',\n",
       "       '여보세요? 혜안이 있어요?', '너희 오빠는 안경을 쓰니? ', '혜안은 요즘 밥도 못 먹고, 잠도 못 자.',\n",
       "       '나 지금 정말 피곤해.', '혜안과 나는 결혼한 지 3개월 되었다.', '이쪽으로 오세요.',\n",
       "       '할아버지는 병원에 계세요. ', '이제 햄버거 지겨워!', '책을 도서관에 반납하세요.',\n",
       "       '이번 달 마지막 날이야.', '포도가 너무 시어.', '나는 신문에서 스포츠 부분만 읽는다.',\n",
       "       '모자를 쓰고 있나요?', '집에 돌아왔을 때, 남편은 소파를 청소하고 있었다.',\n",
       "       '어떤 경우에, 저는 성급하게 결론을 내립니다.', '이번에 중국 처음 가는 거니? ', '니 여동생은 몇 살이니? ',\n",
       "       '나랑 결혼해 줄래?',\n",
       "       '앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 이련들 말만하지 말고 지역별로 다진마늘 비중이 얼마나 되는지 글싸줘랑이니야',\n",
       "       '이번 달에 아기를 낳을 예정이에요.', '좋은 생각이야.', '화내지 마세요, 그냥 장난이었어요.',\n",
       "       '저는 맥주 마실래요.', '토익 시험에서 900점 이상을 받아야 한다.', '나 너무 불안해서 참을 수가 없어. ',\n",
       "       '나는 그에게 그 일을 어서 끝내라고 말했다.', '동대문 시장에 가 보고 싶어요.',\n",
       "       '일본어 공부는 잘 되고 있어요? ', '너 벌써 술 많이 마신 것 같은데.',\n",
       "       '나는 그녀의 갑작스러운 죽음에 놀랐다.',\n",
       "       '성대에 살이꼈노. 살은 빼고 휴가간거노?ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ',\n",
       "       '저것 좀 봐. 강아지가 다리를 다쳤어! ', '저는 늦게 자고 일찍 일어납니다.', '우리는 공통점이 많다.',\n",
       "       '우리 집은 서울 중심에 있다.', '우리 대학은 백 년의 전통을 자랑한다.',\n",
       "       '인터넷에서 영화를 볼 때 어떤 사이트를 이용하세요?', '왜 그렇게 빨리 걷는 거야? ',\n",
       "       '와! 너희 집에 수영장이 있다며? ', '그녀의 눈이 진짜 마음을 나타내고 있었다.',\n",
       "       '정확한 출발 시각은 몇 시인가요?', '한 시간 뒤에 꽃에 물을 줘라.',\n",
       "       '언제나 네가 원하는 것을 얻을 수는 없다.', '나는 내년에 고등학생이 된다.',\n",
       "       '그때 이후로 그녀를 본 적이 없다. '], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testt[k==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8583333333333333"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.score(X_testt,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정상\n"
     ]
    }
   ],
   "source": [
    "label=pred.predict(np.array(['안녕하세요']))\n",
    "if label==1:\n",
    "    print(\"혐오 입니다\")\n",
    "else:\n",
    "    print(\"정상\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
