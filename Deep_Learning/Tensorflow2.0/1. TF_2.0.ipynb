{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[5 2]\n",
      " [1 3]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[5,2],[1,3]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 2],\n",
       "       [1, 3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int32'>\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x.dtype)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3, shape=(2, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [1.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones(shape=(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6, shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros(shape=(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=24, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 1.2866647 , -0.45571974],\n",
       "       [-0.45976248,  0.27735046]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=(2,2),mean=0.,stddev=1.) #정규분포   mean = 0 stddev =1 default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=28, shape=(2, 2), dtype=int32, numpy=\n",
       "array([[2, 8],\n",
       "       [0, 1]])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform(shape=(2,2),minval=0,maxval=10,dtype='int32') #랜덤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[-0.14992791,  0.3181526 ],\n",
       "       [-0.7217185 ,  1.7214775 ]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_value = tf.random.normal(shape=(2,2))\n",
    "a = tf.Variable(initial_value)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[ 2.1564162 , -1.2160028 ],\n",
       "       [-1.1008626 ,  0.68527734]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_value = tf.random.normal(shape=(2,2))\n",
    "a.assign(new_value) #할당\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        assert a[i,j] == new_value[i,j]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[ -8.404855 ,  -2.4224951],\n",
       "       [ -9.847019 , -34.820175 ]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_value = tf.random.normal(shape=(2,2))\n",
    "a.assign_add(added_value) # Add value\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.5907438  -1.0597464 ]\n",
      " [ 0.33317435  0.6277031 ]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.69075274 -0.9709295 ]\n",
      " [ 0.410547   -0.7598145 ]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.10000896 -2.030676  ]\n",
      " [ 0.74372137 -0.13211143]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.01000179 4.1236444 ]\n",
      " [0.55312145 0.01745343]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 1.010052  61.783997 ]\n",
      " [ 1.7386718  1.0176066]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal(shape=(2,2))\n",
    "b = tf.random.normal(shape=(2,2))\n",
    "\n",
    "c = a+b\n",
    "d = tf.square(c)\n",
    "e = tf.exp(d)  #Element-wise\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.9331059  0.5523134 ]\n",
      " [0.71541184 0.825498  ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal(shape=(2,2))\n",
    "b = tf.random.normal(shape=(2,2))\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(a)  # record history of tf.Variable 'a' (if tf.Variable default = tape.watch())\n",
    "    c = tf.sqrt(tf.square(a)+tf.square(b))\n",
    "    dc_da = tape.gradient(c, a)  # dc/da   \n",
    "    print(dc_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 2\n",
    "output_dim = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "w = tf.Variable(tf.random.uniform(shape=(input_dim,output_dim)))\n",
    "b = tf.Variable(tf.zeros(shape=(output_dim,)))\n",
    "\n",
    "def compute_predictions(features):\n",
    "    return tf.matmul(features,w)+b\n",
    "\n",
    "def compute_loss(labels,predictions):\n",
    "    return tf.reduce_mean(tf.square(labels-predictions))\n",
    "@tf.function\n",
    "def train_on_batch(x,y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = compute_predictions(x)\n",
    "        loss = compute_loss(y, predictions)\n",
    "        dloss_dw, dloss_db = tape.gradient(loss,[w,b])\n",
    "        \n",
    "    w.assign_sub(learning_rate*dloss_dw)\n",
    "    b.assign_sub(learning_rate*dloss_db)\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 2.0], [3.0, 6.0]]\n",
      "[[1.0], [0.0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "a=[[1.,2.],[3.,6.]]\n",
    "b=[[1.],[0.]]\n",
    "random.Random(133).shuffle(a)\n",
    "random.Random(133).shuffle(b)  #Same seed \n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((a,b)) #tuple shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(buffer_size=5).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    for step,(x,y) in enumerate(dataset):\n",
    "        loss = train_on_batch(x,y)\n",
    "        \n",
    "    print('Epoch %d: 마지막 배치의 손실값 = %.4f' %(epoch,float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class Linear(Layer):\n",
    "    \n",
    "    def __init__(self, units=32): #units = num of output node\n",
    "        super(Linear,self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1],self.units),initializer='random_normal',trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),initializer='random_normal',trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w)+self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = Linear(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()\n",
    "        self.linear_1 = Linear(32)\n",
    "        self.linear_2 = Linear(32)\n",
    "        self.linear_3 = Linear(10)\n",
    "        \n",
    "    def call(self):\n",
    "        x = self.linear_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return self.linear_3(x)\n",
    "    \n",
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.33324\n"
     ]
    }
   ],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "y = [1.,2.,3.]\n",
    "pred = [1.,2.,1.]\n",
    "print(bce(y,pred).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.4166667\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state([0,0,1,1],[0,1,0,0])\n",
    "print(m.result().numpy())\n",
    "m.update_state([1,1,1,1],[0,1,1,0])  # 이어서 데이터를 input 후 result 갱신\n",
    "print(m.result().numpy())\n",
    "m.reset_states()\n",
    "print(m.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) # first do softmax\n",
    "optimizer =tf.keras.optimizers.Adam()\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "for step,(x,y) in enumerate(dataset):\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        logits = model(x) #forward propagation\n",
    "        loss_value = loss(y,logits)\n",
    "    \n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients,model.trainable_weights)) #tf.keras.optimizers.apply_gradients\n",
    "    accuracy.update_state(y,logits) # tf.keras.metrics.update_state\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step)\n",
    "        print(float(loss_value))\n",
    "        print(float(accuracy.result())) # made by accumulated data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.reset_states()\n",
    "\n",
    "for step, (x,y) in enumerate(testset):\n",
    "    logits = model(x)\n",
    "    accuracy.update_state(y,logits)\n",
    "    \n",
    "print(float(accuracy.result()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
