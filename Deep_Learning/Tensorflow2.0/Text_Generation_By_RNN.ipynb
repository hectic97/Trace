{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Generation_By_RNN",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rucceqGs5YK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b9a5ee07-bbca-4448-df61-86e40b7ee10c"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNf3y1-Jtr8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "841767ff-e220-416d-af26-ef5b43eb1c0c"
      },
      "source": [
        "text = open('../content/KakaoTalk_20200311_1733_24_621_장윤호.txt','rb').read().decode(encoding='utf-8')\n",
        "print('Text Length : {}'.format(len(text)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text Length : 840185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7kP6TEcvAId",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "db07a576-e1be-4bef-808a-4f9cf3853cb7"
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "장윤호 님과 카카오톡 대화\r\n",
            "저장한 날짜 : 2020-03-11 17:33:27\r\n",
            "\r\n",
            "--------------- 2019년 9월 15일 일요일 ---------------\r\n",
            "[장윤호] [오후 4:54] 0퍼대 ㅊㅊ\r\n",
            "[장윤호] [오후 4:54] 내몫까지\r\n",
            "[장윤호] [오후 4:54] 즐겨줘\r\n",
            "[정영준] [오후 5:35] 2연패..\r\n",
            "[정영준] [오후 5:35] 너도빨리 플래 ㄱ\r\n",
            "[장윤호] [오후 5:39] 난 다른것들을하려고\r\n",
            "[장윤호] [\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OnOf4bivC0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab=sorted(set(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ5WJBLFvI2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0aa59d34-5756-48d7-8a52-bb20ea08db3c"
      },
      "source": [
        "print('Unique letters : {}'.format(len(vocab)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique letters : 1624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t-6NVcbvXCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "3f166f68-0f0c-46e3-e896-3d85256bbe9a"
      },
      "source": [
        "vocab[:20]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " '\\r',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " '#',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Xa_z9lvdR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "char2idx = {u:i for i,u in enumerate(vocab)} #{'아':3}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text]) # text to int"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFBqdfBSv0sl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "17358340-c8a4-4670-94f8-3c1773628944"
      },
      "source": [
        "for char,_ in zip(char2idx,range(20)):\n",
        "    print('{}:{}'.format(repr(char),char2idx[char]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'\\n':0\n",
            "'\\r':1\n",
            "' ':2\n",
            "'!':3\n",
            "'\"':4\n",
            "'#':5\n",
            "'%':6\n",
            "'&':7\n",
            "\"'\":8\n",
            "'(':9\n",
            "')':10\n",
            "'*':11\n",
            "'+':12\n",
            "',':13\n",
            "'-':14\n",
            "'.':15\n",
            "'/':16\n",
            "'0':17\n",
            "'1':18\n",
            "'2':19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ4GMGdYwA7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a1fb861f-5d2c-4b02-aa43-58b728e74a08"
      },
      "source": [
        "print('{} ---- mapping to int --> {}'.format(repr(text[:15]),text_as_int[:15]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'장윤호 님과 카카오톡 대화\\r' ---- mapping to int --> [1183 1143 1574    2  419  212    2 1362 1362 1089 1445    2  440 1582\n",
            "    1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHeBN_FdwcSN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "851aea09-d145-4136-e7f3-5acf2b3a4186"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)/seq_length\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "    print(idx2char[i.numpy()])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "장\n",
            "윤\n",
            "호\n",
            " \n",
            "님\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcvIl_pEwyY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "3a3ab423-bc16-4483-94a8-c43f6bb071ae"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)# tf.data.Dataset.from_tensor_slices.batch 개수 남으면 버리기  \n",
        "# seq_length+1  batch to  trainset 1~100   testset 2~101\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'장윤호 님과 카카오톡 대화\\r\\n저장한 날짜 : 2020-03-11 17:33:27\\r\\n\\r\\n--------------- 2019년 9월 15일 일요일 ---------------\\r\\n[장윤'\n",
            "'호] [오후 4:54] 0퍼대 ㅊㅊ\\r\\n[장윤호] [오후 4:54] 내몫까지\\r\\n[장윤호] [오후 4:54] 즐겨줘\\r\\n[정영준] [오후 5:35] 2연패..\\r\\n[정영준] [오후 5:35'\n",
            "'] 너도빨리 플래 ㄱ\\r\\n[장윤호] [오후 5:39] 난 다른것들을하려고\\r\\n[장윤호] [오후 5:39] 축구도하고\\r\\n[장윤호] [오후 5:39] 유튜브도보고\\r\\n[장윤호] [오후 5:3'\n",
            "'9] 드라마도보고\\r\\n[정영준] [오후 8:18] 좋지\\r\\n[정영준] [오후 8:18] 나도\\r\\n[정영준] [오후 8:18] 담주부턴\\r\\n[정영준] [오후 8:18] 롤 막\\r\\n[정영준] ['\n",
            "'오후 8:18] 하루6시개\\r\\n[정영준] [오후 8:18] 간\\r\\n[정영준] [오후 8:18] 평일에못함ㅋㅋ\\r\\n[정영준] [오후 8:18] 진짜학교생활시작\\r\\n[정영준] [오후 8:18]'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dal8fk2exSTm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed47cd59-7d30-408e-c0f3-e252415409fd"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text,target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target) \n",
        "print(dataset)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MapDataset shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9pwRQHfxvCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "2d545eea-fc2a-4c75-9120-1a0ef0046143"
      },
      "source": [
        "for input_example,target_example in dataset.take(1):\n",
        "    print('input data:',repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('output data:',repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input data: '장윤호 님과 카카오톡 대화\\r\\n저장한 날짜 : 2020-03-11 17:33:27\\r\\n\\r\\n--------------- 2019년 9월 15일 일요일 ---------------\\r\\n[장'\n",
            "output data: '윤호 님과 카카오톡 대화\\r\\n저장한 날짜 : 2020-03-11 17:33:27\\r\\n\\r\\n--------------- 2019년 9월 15일 일요일 ---------------\\r\\n[장윤'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKLJ04zpyHoj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "b4a556b0-cb3b-41e9-c171-f8e695b09d98"
      },
      "source": [
        "for i,(input_idx,target_idx) in enumerate(zip(input_example[:5],target_example[:5])):\n",
        "    print(\"{:4d} iter\".format(i))\n",
        "    print(\" input: {} ({:s})\".format(input_idx,idx2char[input_idx]))\n",
        "    print(\" prediction: {} ({:s})\".format(target_idx,idx2char[target_idx]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0 iter\n",
            " input: 1183 (장)\n",
            " prediction: 1143 (윤)\n",
            "   1 iter\n",
            " input: 1143 (윤)\n",
            " prediction: 1574 (호)\n",
            "   2 iter\n",
            " input: 1574 (호)\n",
            " prediction: 2 ( )\n",
            "   3 iter\n",
            " input: 2 ( )\n",
            " prediction: 419 (님)\n",
            "   4 iter\n",
            " input: 419 (님)\n",
            " prediction: 212 (과)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6CGdXhpyyu2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "81c3cbc5-633d-4f7d-e576-709470720110"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGU7oeoFzGlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "\n",
        "embedding_dim = 512\n",
        "\n",
        "rnn_units = 1024\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6u5cC7wz61x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size,embedding_dim,rnn_units,batch_size):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size,embedding_dim,batch_input_shape=[batch_size,None]),\n",
        "        tf.keras.layers.LSTM(rnn_units,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0n6YP1b01Fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size=vocab_size,embedding_dim=embedding_dim,rnn_units=rnn_units,batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFC5jJkL1iNu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1f875bf-8a43-45ec-800f-48e32fe6fab7"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 1624)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opSA_s4n1iSC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "68288582-6709-476d-e54a-b5d1125e2ef4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 512)           831488    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (64, None, 1024)          6295552   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 1624)          1664600   \n",
            "=================================================================\n",
            "Total params: 8,791,640\n",
            "Trainable params: 8,791,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDm5PfiR1iQi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "200c016b-e03b-43a8-f166-10634a562367"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0],1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 794, 1436,  828,  453, 1115,  852, 1595,   90,  303,  470,  848,\n",
              "       1078, 1131, 1525,   24, 1230, 1344, 1280,  954,  484,   88, 1372,\n",
              "       1198,  775,  294,  701, 1277,  755,  711, 1454, 1541,  109,  865,\n",
              "       1380,  833,  585,  512,  679, 1141,  762,  820, 1158,  808,  743,\n",
              "        262, 1329, 1044, 1429,  400,  821,  735,  359,  433,  643, 1383,\n",
              "        961,  297,  274,  840,  512,  483,  514,  701,  546, 1020, 1041,\n",
              "        191,  786,  739, 1023, 1594,  634,  342,  625, 1373,   39,  393,\n",
              "       1272,   79, 1144,  730, 1565, 1522, 1242, 1158,  399,  167, 1179,\n",
              "       1146,  386,  937,  767, 1197,  737, 1012,  621, 1365,   37,  175,\n",
              "       1273])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yDUQzbo3Zay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "929087c0-1260-4ad3-eb27-7d7bc5b8fff2"
      },
      "source": [
        "print('input: \\n',repr(''.join(idx2char[input_example_batch[0]])))\n",
        "print('\\nprediction for next letter: \\n',repr(''.join(idx2char[sampled_indices])))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input: \n",
            " '정영준] [오후 7:05] ㅁㄹ\\r\\n[정영준] [오후 7:05] 5판3선이니\\r\\n[장윤호] [오후 7:05] 오 5판3선임?\\r\\n[정영준] [오후 7:05] Ig  vs  그리핀\\r\\n[정'\n",
            "\n",
            "prediction for next letter: \n",
            " '봬털빴덤욕뿌훅z꾹돕뽄열웨핀7죠출쩝슴됬x컥절벼꼽몬쩍밴묹퉁핵ㄸ사케뺄랴딜먼유벌빚의브밝까쳐얀탤뉴빛및넓닭른켰시꽃깸뻑딜됩딥몬뙤악앵겧볼밖않후룻낸롸컨F누째o율밀혁픔쥐의뉘갴잠융농쉘벙젇바씅롬캄D건쨌'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsyxvCbx30f4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0361e14b-cf6d-4c43-cb41-3b63f8ed8bd5"
      },
      "source": [
        "def loss(labels,logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels,logits,from_logits=True) #softmax\n",
        "\n",
        "example_batch_loss = loss(target_example_batch,example_batch_predictions)\n",
        "print(example_batch_predictions.shape)\n",
        "print(example_batch_loss.numpy().mean())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 1624)\n",
            "7.3933654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhx8iVB24MRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "model.compile(loss=loss,optimizer='Adam')\n",
        "checkpoint_dir='./training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir,\"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiIDB8xP4YmB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ef0e8fe-5692-4a23-c86f-5064906c1ae0"
      },
      "source": [
        "EPOCHS=50\n",
        "history = model.fit(dataset,epochs=EPOCHS,callbacks=[checkpoint_callback])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 129 steps\n",
            "Epoch 1/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 2.7058\n",
            "Epoch 2/50\n",
            "129/129 [==============================] - 18s 137ms/step - loss: 1.5713\n",
            "Epoch 3/50\n",
            "129/129 [==============================] - 18s 139ms/step - loss: 1.4628\n",
            "Epoch 4/50\n",
            "129/129 [==============================] - 18s 138ms/step - loss: 1.4079\n",
            "Epoch 5/50\n",
            "129/129 [==============================] - 18s 140ms/step - loss: 1.3699\n",
            "Epoch 6/50\n",
            "129/129 [==============================] - 18s 140ms/step - loss: 1.3413\n",
            "Epoch 7/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 1.3180\n",
            "Epoch 8/50\n",
            "129/129 [==============================] - 18s 141ms/step - loss: 1.2976\n",
            "Epoch 9/50\n",
            "129/129 [==============================] - 18s 141ms/step - loss: 1.2789\n",
            "Epoch 10/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 1.2618\n",
            "Epoch 11/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 1.2464\n",
            "Epoch 12/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 1.2315\n",
            "Epoch 13/50\n",
            "129/129 [==============================] - 19s 145ms/step - loss: 1.2161\n",
            "Epoch 14/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 1.2016\n",
            "Epoch 15/50\n",
            "129/129 [==============================] - 18s 142ms/step - loss: 1.1867\n",
            "Epoch 16/50\n",
            "129/129 [==============================] - 19s 144ms/step - loss: 1.1728\n",
            "Epoch 17/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 1.1583\n",
            "Epoch 18/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 1.1457\n",
            "Epoch 19/50\n",
            "129/129 [==============================] - 19s 145ms/step - loss: 1.1308\n",
            "Epoch 20/50\n",
            "129/129 [==============================] - 19s 144ms/step - loss: 1.1172\n",
            "Epoch 21/50\n",
            "129/129 [==============================] - 19s 144ms/step - loss: 1.1031\n",
            "Epoch 22/50\n",
            "129/129 [==============================] - 19s 144ms/step - loss: 1.0890\n",
            "Epoch 23/50\n",
            "129/129 [==============================] - 18s 142ms/step - loss: 1.0749\n",
            "Epoch 24/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 1.0611\n",
            "Epoch 25/50\n",
            "129/129 [==============================] - 18s 142ms/step - loss: 1.0463\n",
            "Epoch 26/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 1.0321\n",
            "Epoch 27/50\n",
            "129/129 [==============================] - 19s 144ms/step - loss: 1.0174\n",
            "Epoch 28/50\n",
            "129/129 [==============================] - 19s 144ms/step - loss: 1.0029\n",
            "Epoch 29/50\n",
            "129/129 [==============================] - 19s 143ms/step - loss: 0.9889\n",
            "Epoch 30/50\n",
            "129/129 [==============================] - 18s 142ms/step - loss: 0.9740\n",
            "Epoch 31/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 0.9592\n",
            "Epoch 32/50\n",
            "129/129 [==============================] - 19s 144ms/step - loss: 0.9458\n",
            "Epoch 33/50\n",
            "129/129 [==============================] - 18s 142ms/step - loss: 0.9311\n",
            "Epoch 34/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 0.9180\n",
            "Epoch 35/50\n",
            "129/129 [==============================] - 19s 144ms/step - loss: 0.9036\n",
            "Epoch 36/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 0.8907\n",
            "Epoch 37/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 0.8785\n",
            "Epoch 38/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 0.8656\n",
            "Epoch 39/50\n",
            "129/129 [==============================] - 18s 142ms/step - loss: 0.8474\n",
            "Epoch 40/50\n",
            "129/129 [==============================] - 18s 142ms/step - loss: 0.8265\n",
            "Epoch 41/50\n",
            "129/129 [==============================] - 18s 141ms/step - loss: 0.8140\n",
            "Epoch 42/50\n",
            "129/129 [==============================] - 18s 142ms/step - loss: 0.8022\n",
            "Epoch 43/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 0.7905\n",
            "Epoch 44/50\n",
            "129/129 [==============================] - 18s 141ms/step - loss: 0.7798\n",
            "Epoch 45/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 0.7691\n",
            "Epoch 46/50\n",
            "129/129 [==============================] - 19s 144ms/step - loss: 0.7595\n",
            "Epoch 47/50\n",
            "129/129 [==============================] - 19s 144ms/step - loss: 0.7493\n",
            "Epoch 48/50\n",
            "129/129 [==============================] - 18s 143ms/step - loss: 0.7397\n",
            "Epoch 49/50\n",
            "129/129 [==============================] - 19s 144ms/step - loss: 0.7312\n",
            "Epoch 50/50\n",
            "129/129 [==============================] - 19s 145ms/step - loss: 0.7213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VocEgvlm4jmo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "235c5635-6a05-4d57-b6c2-bc2fc509fe49"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_50'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fct4A5Bf5vFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "81bb19fe-420b-4374-eb48-d7930d19d4fb"
      },
      "source": [
        "model = build_model(vocab_size,embedding_dim,rnn_units,batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "model.summary()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (1, None, 512)            831488    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (1, None, 1024)           6295552   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (1, None, 1624)           1664600   \n",
            "=================================================================\n",
            "Total params: 8,791,640\n",
            "Trainable params: 8,791,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs5pPc6s6GQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model,start_string):\n",
        "    num_generate = 1000\n",
        "\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval,0)\n",
        "\n",
        "    text_generated=[]\n",
        "    temperature = 0.80\n",
        "\n",
        "    model.reset_states() #stateful = True 로 생성된 초기 state 초기화\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "\n",
        "        predictions = tf.squeeze(predictions,0)\n",
        "\n",
        "        predictions = predictions/temperature  # reduce greedy\n",
        "        predicted_id = tf.random.categorical(predictions,1)[-1,0].numpy()\n",
        "        \n",
        "        input_eval = tf.expand_dims([predicted_id],0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string+''.join(text_generated))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrM33q-I__8_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "e50607e2-dab0-4298-a3dd-6df25570fa46"
      },
      "source": [
        "print(generate_text(model,start_string=u\"[장윤호] [오전\"))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[장윤호] [오전 2:18] 그렇게얘기하냐\r\n",
            "[정영준] [오전 1:27] 전화이나\r\n",
            "[장윤호] [오전 1:00] 아침부터\r\n",
            "[정영준] [오전 2:51] ㅋㅋㅋ\r\n",
            "[정영준] [오전 1:36] 해도안됨\r\n",
            "[장윤호] [오전 3:02] ㅋㅋㅋㅋㅋㅋ\r\n",
            "[장윤호] [오전 2:37] 학교도다니느라\r\n",
            "[장윤호] [오전 5:24] 자주이뭐냐\r\n",
            "[정영준] [오전 2:35] ㅋㅋㅋㅋㅋㅋㅋㅋㅋ\r\n",
            "[장윤호] [오전 2:26] 먹으면되네\r\n",
            "[정영준] [오전 12:51] 개덥지도\r\n",
            "[장윤호] [오전 1:03] 진욱이 형 안녕 \r\n",
            "[장윤호] [오전 1:08] 공부를하기로\r\n",
            "[장윤호] [오전 2:30] 일단그냥\r\n",
            "[정영준] [오전 2:02] 막 8시부터 2시까지 11시경때\r\n",
            "[장윤호] [오전 2:33] 문과면\r\n",
            "[장윤호] [오전 12:46] 나도\r\n",
            "[장윤호] [오전 1:38] 하니까\r\n",
            "[장윤호] [오후 7:57] 그냥 교수님들으로\r\n",
            "[정영준] [오후 9:23] 아니 세계지\r\n",
            "[정영준] [오후 11:05] 고전파\r\n",
            "[장윤호] [오전 1:30] 오오전 2:48] 탄사람이\r\n",
            "[정영준] [오전 2:30] 진호가\r\n",
            "[정영준] [오전 1:57] 시스템종료창\r\n",
            "[정영준] [오전 12:32] 너무싫네\r\n",
            "[정영준] [오전 5:25] ..\r\n",
            "[장윤호] [오전 12:30] 가져가서\r\n",
            "[장윤호] [오전 3:43] ㄹㅇ\r\n",
            "[정영준] [오전 2:50] ?????\r\n",
            "[정영준] [오전 12:12] 사랑을했다~\r\n",
            "[정영준] [오전 12:48] 안하나 [오후 4:30] 초콜릿보다\r\n",
            "[장윤호] [오후 3:46] 시원하지\r\n",
            "[정영준] [오후 6:06] 그렇구나\r\n",
            "[정영준] [오후 7:38] 이건\r\n",
            "[정영준] [오후 7:56] 판수가야돼서\r\n",
            "[장윤호] [오후 2:51] 너의소확히도\r\n",
            "[장윤호] [오후 5:23] ㅇㅇ\r\n",
            "[정영준] [오후 8:11] 그렇게\r\n",
            "[정영준] [오후 7:05] 근데 너무\r\n",
            "[정영준] [오후 6:17] 이지랄하는겆\r\n",
            "[정영준] [오후 10:54] 나가잖앜\r\n",
            "[장윤호] [오전 2:49] 어디서\r\n",
            "[정영준] [오전 1:05]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDwfiJj6AODx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaH8t2dbAOQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}